resources:
  jobs:
    WF_Session_Historic_Load:
      name: WF_Session_Historic_Load
      parameters:
        - name: catalog_name
          default: ${var.catalog_name}
      tasks:
        - task_key: Creating_Session_tables
          notebook_task:
            notebook_path: ../metrics/data_platform/Gold/NB_Session_DDL.py
            base_parameters:
              catalog_name: ${var.catalog_name}
            source: WORKSPACE
          job_cluster_key: Metric_Job_Cluster
        - task_key: Fact_Session_Load
          depends_on:
            - task_key: Creating_Session_tables
          notebook_task:
            notebook_path: ../metrics/data_platform/Gold/NB_Fact_sessions.py
            base_parameters:
              catalog_name: ${var.catalog_name}
            source: WORKSPACE
          job_cluster_key: Metric_Job_Cluster
        - task_key: Fact_Session_Events_load
          depends_on:
            - task_key: Fact_Session_Load
          notebook_task:
            notebook_path: ../metrics/data_platform/Gold/NB_Fact_session_events.py
            base_parameters:
              catalog_name: ${var.catalog_name}
            source: WORKSPACE
          job_cluster_key: Metric_Job_Cluster

      job_clusters:
        - job_cluster_key: Metric_Job_Cluster
          new_cluster:
            cluster_name: ""
            spark_version: 17.1.x-scala2.13
            node_type_id: Standard_DS3_v2
            spark_env_vars:
              PYSPARK_PYTHON: /databricks/python3/bin/python3
            data_security_mode: DATA_SECURITY_MODE_STANDARD
            runtime_engine: STANDARD
            kind: CLASSIC_PREVIEW
            is_single_node: false
            autoscale:
              min_workers: 2
              max_workers: 8

      queue:
        enabled: true